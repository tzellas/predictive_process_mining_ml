{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1xw8BXUw58L9IwoeL0moMoPxyrpRzeEDe",
      "authorship_tag": "ABX9TyMhPL8+UHSR6ZlVXzackF1m",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tzellas/predictive_process_mining_ml/blob/master/event_log_preprocessing.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Predictive Process Mining Diploma Theses\n",
        "\n",
        "**Description**\n",
        "\n",
        "\n",
        "---\n",
        "ICL Prompting on LLMs with RAG for Predictive Process Monitoring.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "YVo7eLdS4MSR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Event Log Preprocessing\n",
        "\n",
        "\n",
        "---\n",
        "Here we will parse the XES event log, extract prefixes and store them as embeddings in a vector index.\n"
      ],
      "metadata": {
        "id": "8JT0-P1Tk-qH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "import pandas as pd\n",
        "import pm4py\n",
        "import csv\n",
        "\n",
        "\n",
        "trace_identifier = \"case:concept:name\"\n",
        "\n",
        "event_logs = {\n",
        "                  \"2019\" : \"BPI_Challenge_2019.xes\",\n",
        "                  \"2020\" : \"BPI_Challenge_2020.xes\"\n",
        "                }\n",
        "def read_clean_log(event_log_id):\n",
        "  xes_data_path = \"/content/drive/MyDrive/Predictive Process Monitoring /data/XES FILES/\"\n",
        "\n",
        "  xes_log  = pm4py.read_xes(xes_data_path + event_logs[event_log_id])\n",
        "  df_log = pm4py.convert_to_dataframe(xes_log)\n",
        "  df_log = df_log.sort_values([trace_identifier, \"time:timestamp\"]).reset_index(drop=True)\n",
        "  keep_cols = [\n",
        "      c for c in df_log.columns if not c.startswith(\"case:\") or c == trace_identifier\n",
        "  ]\n",
        "  df_log = df_log[keep_cols].copy()\n",
        "  return df_log\n",
        "\n",
        "\n",
        "\n",
        "def build_prefixes(df_log: pd.DataFrame, base: int = 1, gap: int = 3):\n",
        "  seen_prefixes = set()\n",
        "  prefixes = []\n",
        "  j_map = {}\n",
        "  j = 1\n",
        "  for trace_id ,df_trace in df_log.groupby(trace_identifier, sort=False):\n",
        "\n",
        "    if len(df_trace) <= 2:\n",
        "      continue\n",
        "\n",
        "    df_trace = df_trace.reset_index(drop=True)\n",
        "\n",
        "    prefix = []\n",
        "    values = {}\n",
        "\n",
        "    for i in range(base, len(df_trace)-1, gap):\n",
        "      if i == base:\n",
        "        start = 0\n",
        "      else:\n",
        "        start = i-gap+1\n",
        "      for event_index in range(start,i+1):\n",
        "        prefix.append(df_trace.iloc[event_index][\"concept:name\"])\n",
        "        cl_list = ','.join(prefix)\n",
        "\n",
        "        event = df_trace.iloc[event_index]\n",
        "        for key, value in event.items():\n",
        "          if key in {\"concept:name\", trace_identifier}:\n",
        "            continue\n",
        "          if key not in j_map:\n",
        "            j_map[key] = ''.join([part[:2] for part in key.split(':')])\n",
        "            j += 1\n",
        "          values[j_map[key]] = str(value)\n",
        "      if cl_list in seen_prefixes:\n",
        "        continue\n",
        "      seen_prefixes.add(cl_list)\n",
        "\n",
        "      final_prefix_string = f\"{cl_list} - Values: Values: {values} - {df_trace.iloc[i+1][\"concept:name\"]}\"\n",
        "      prefixes.append(final_prefix_string)\n",
        "  return prefixes\n",
        "\n",
        "\n",
        "pref_list_2020 = build_prefixes(read_clean_log(\"2020\"))\n",
        "print(pref_list_2020)\n"
      ],
      "metadata": {
        "id": "W7S0xA6z3L_s",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 418
        },
        "outputId": "c0c7d5bf-b924-4622-9e07-cf7f31158570"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'pm4py'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-1522999581.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mdrive\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/drive'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mpm4py\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcsv\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'pm4py'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def convert_to_csv(prefix_list, event_log_id):\n",
        "  rows = []\n",
        "  for row in prefix_list:\n",
        "    rows.append((f\"{' - '.join(row.split(' - ', 2)[:2]).strip()}\",f\"{row.split(' - ',2)[2].strip()}\" ))\n",
        "\n",
        "  csv_relults_path = f\"/content/drive/MyDrive/Predictive Process Monitoring /data/CSV RESULTS/{event_logs[event_log_id].removesuffix(\"xes\")}csv\"\n",
        "\n",
        "  with open(csv_relults_path, \"w\", newline=\"\", encoding=\"utf-8\") as f:\n",
        "        w = csv.writer(f)\n",
        "        w.writerow([\"prefix\", \"prediction\"])\n",
        "        w.writerows(rows)\n",
        "\n",
        "convert_to_csv(pref_list_2020, \"2020\")\n",
        "\n",
        "\n",
        "def reduced_csv(event_log_id, max_rows: int = 300):\n",
        "    csv_relults_path = f\"/content/drive/MyDrive/Predictive Process Monitoring /data/CSV RESULTS/{event_logs[event_log_id].removesuffix(\"xes\")}csv\"\n",
        "    reduced_path = f\"/content/drive/MyDrive/Predictive Process Monitoring /data/CSV RESULTS/reduced_{event_logs[event_log_id].removesuffix(\"xes\")}csv\"\n",
        "    with open(csv_relults_path, \"r\", encoding=\"utf-8\", newline=\"\") as f:\n",
        "      reader = csv.reader(f)\n",
        "      header = next(reader)\n",
        "      rows = []\n",
        "      for i, row in enumerate(reader):\n",
        "          if i >= max_rows:\n",
        "              break\n",
        "          rows.append(row)\n",
        "\n",
        "    with open(reduced_path, \"w\", encoding=\"utf-8\", newline=\"\") as f:\n",
        "        writer = csv.writer(f)\n",
        "        writer.writerow(header)\n",
        "        writer.writerows(rows)\n",
        "\n",
        "reduced_csv(\"2020\")"
      ],
      "metadata": {
        "id": "29PwAm_7V-Fc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def search_csv_column(\n",
        "    event_log_id,\n",
        "    column_name: str,\n",
        "    search_string: str\n",
        "):\n",
        "    matches = []\n",
        "    csv_relults_path = f\"/content/drive/MyDrive/Predictive Process Monitoring /data/CSV RESULTS/{event_logs[event_log_id].removesuffix('xes')}csv\"\n",
        "\n",
        "    with open(csv_relults_path, newline=\"\", encoding=\"utf-8\") as f:\n",
        "        reader = csv.DictReader(f)\n",
        "\n",
        "        if column_name not in reader.fieldnames:\n",
        "            raise ValueError(f\"Column '{column_name}' not found\")\n",
        "\n",
        "        for row in reader:\n",
        "            if search_string in row[column_name]:\n",
        "                matches.append(row)\n",
        "\n",
        "    return matches\n"
      ],
      "metadata": {
        "id": "XuyWZKSt4aws"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "if6I6hvUSrqS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f5fddd21-a3c7-426b-f41e-f861a0ebf21d"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'prefix': \"Permit SUBMITTED by EMPLOYEE,Permit APPROVED by ADMINISTRATION,Permit REJECTED by SUPERVISOR,Permit REJECTED by EMPLOYEE,Permit SUBMITTED by EMPLOYEE,Permit APPROVED by ADMINISTRATION,Permit APPROVED by BUDGET OWNER,Start trip,Permit FINAL_APPROVED by SUPERVISOR,End trip,Declaration SUBMITTED by EMPLOYEE,Declaration REJECTED by ADMINISTRATION,Declaration REJECTED by EMPLOYEE,Declaration SUBMITTED by EMPLOYEE - Values: Values: {'id': 'st_step 27246_0', 'orre': 'STAFF MEMBER', 'titi': '2018-11-28 15:49:59+00:00', 'orro': 'EMPLOYEE'}\",\n",
              "  'prediction': 'Declaration APPROVED by ADMINISTRATION'}]"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ],
      "source": [
        "search_csv_column(\"2020\", \"prefix\", \"Permit SUBMITTED by EMPLOYEE,Permit APPROVED by ADMINISTRATION,Permit REJECTED by SUPERVISOR,Permit REJECTED by EMPLOYEE,Permit SUBMITTED by EMPLOYEE,Permit APPROVED by ADMINISTRATION,Permit APPROVED by BUDGET OWNER,Start trip,Permit FINAL_APPROVED by SUPERVISOR,End trip,Declaration SUBMITTED by EMPLOYEE,Declaration REJECTED by ADMINISTRATION,Declaration REJECTED by EMPLOYEE,Declaration SUBMITTED by EMPLOYEE - Values: Values: {'id': 'st_step 27246_0', 'orre': 'STAFF MEMBER', 'titi': '2018-11-28\")"
      ]
    }
  ]
}